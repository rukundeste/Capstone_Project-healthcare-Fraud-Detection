{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52717b44-6220-40ff-987a-677add04e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "145c1e74-33fb-42a0-9051-d26e87028539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display setting to better visualize notebook\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',10)\n",
    "pd.set_option('display.width',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13926c55-828d-46af-8027-c8bcb526d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Aggregated  data\n",
    "df = pd.read_csv('New_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6812233-8428-407d-82dd-217ae3f738ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5410, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e64ba9-c827-4ece-922a-da915bd61213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>IP_average_claim_duration</th>\n",
       "      <th>OP_average_claim_duration</th>\n",
       "      <th>PotentialFraud</th>\n",
       "      <th>IP_Claims_Total</th>\n",
       "      <th>OP_Claims_Total</th>\n",
       "      <th>IP_Averagedaysinhospital</th>\n",
       "      <th>IPAnnualDeductibleAmt</th>\n",
       "      <th>OPAnnualDeductibleAmt</th>\n",
       "      <th>IP_total_diagnosis</th>\n",
       "      <th>OP_total_diagnosis</th>\n",
       "      <th>IP_total_procedures</th>\n",
       "      <th>OP_total_procedures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>97000.0</td>\n",
       "      <td>7640.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRV51003</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>573000.0</td>\n",
       "      <td>32670.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRV51004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRV51005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280910.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRV51007</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>14710.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Provider  IP_average_claim_duration  OP_average_claim_duration PotentialFraud  IP_Claims_Total  OP_Claims_Total  IP_Averagedaysinhospital  IPAnnualDeductibleAmt  OPAnnualDeductibleAmt  IP_total_diagnosis  OP_total_diagnosis  IP_total_procedures  OP_total_procedures\n",
       "0  PRV51001                        5.0                        1.0             No          97000.0           7640.0                       5.0                  890.0                  475.0                36.0                44.0                  3.0                  0.0\n",
       "1  PRV51003                        5.0                        2.0            Yes         573000.0          32670.0                       5.0                  823.0                  665.0               503.0               190.0                 48.0                  0.0\n",
       "2  PRV51004                        0.0                        1.0             No              0.0          52170.0                       0.0                  454.0                  601.0                 0.0               385.0                  0.0                  0.0\n",
       "3  PRV51005                        0.0                        1.0            Yes              0.0         280910.0                       0.0                  399.0                  476.0                 0.0              3016.0                  0.0                  0.0\n",
       "4  PRV51007                        5.0                        1.0             No          19000.0          14710.0                       5.0                  424.0                  431.0                22.0               193.0                  1.0                  0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54df263e-6502-42a2-bf98-7a1448cdc442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8734\n",
      "Precision: 0.4167\n",
      "Recall: 0.8911\n",
      "F1-score: 0.5678\n",
      "ROC-AUC: 0.9583\n",
      "Confusion Matrix:\n",
      " [[855 126]\n",
      " [ 11  90]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Important Features:\n",
      "                     Feature  Importance\n",
      "2            IP_Claims_Total    3.104207\n",
      "8         OP_total_diagnosis    0.687930\n",
      "7         IP_total_diagnosis    0.563876\n",
      "3            OP_Claims_Total    0.553771\n",
      "0  IP_average_claim_duration    0.496939\n",
      "9        IP_total_procedures    0.409807\n",
      "4   IP_Averagedaysinhospital    0.232891\n",
      "6      OPAnnualDeductibleAmt    0.099864\n",
      "5      IPAnnualDeductibleAmt    0.076620\n",
      "1  OP_average_claim_duration    0.062931\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'top_10_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Plot the top 10 features\u001b[39;00m\n\u001b[0;32m     56\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m---> 57\u001b[0m sns\u001b[38;5;241m.\u001b[39mbarplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mtop_10_features, palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m, legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     58\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTop 10 Features for Fraud Detection (Logistic Regression)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     59\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance (Absolute Coefficient)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_10_features' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df.drop(columns=['Provider', 'PotentialFraud'])\n",
    "y = df['PotentialFraud'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train the model with class_weight='balanced'\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = log_reg.predict(X_test)\n",
    "y_prob = log_reg.predict_proba(X_test)[:, 1]  # Probabilities for ROC curve\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(f'Confusion Matrix:\\n {conf_matrix}')\n",
    "\n",
    "# Visualize the ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, color='blue', label='ROC Curve')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')  \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Logistic Regression')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Feature Importances (Logistic Regression Coefficients)\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': np.abs(log_reg.coef_[0])})\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(\"Top Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Plot the top 10 features\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x='Importance', y='Feature', data=top_10_features, palette='viridis', hue='Feature', legend=False)\n",
    "plt.title('Top 10 Features for Fraud Detection (Logistic Regression)')\n",
    "plt.xlabel('Importance (Absolute Coefficient)')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2882978c-3f4a-466f-804c-bf875c216bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the confusion matrix visualizer\n",
    "cm_viz = ConfusionMatrix(log_reg, classes=['No Fraud', 'Fraud'])\n",
    "# Fit and evaluate the model\n",
    "cm_viz.fit(X_train, y_train)\n",
    "cm_viz.score(X_test, y_test)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4809b56a-23e3-471d-a61c-af9f55ece8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Decision tree model\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['Provider', 'PotentialFraud'])\n",
    "y = df['PotentialFraud'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train the Decision Tree model with class_weight='balanced'\n",
    "dt_model = DecisionTreeClassifier(max_depth=5, random_state=42, class_weight='balanced')  \n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = dt_model.predict(X_test)\n",
    "y_prob = dt_model.predict_proba(X_test)[:, 1]  # Probabilities for ROC curve\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(f'Confusion Matrix:\\n {conf_matrix}')\n",
    "\n",
    "# Visualize the ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, color='blue', label='ROC Curve')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')  \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Decision Tree')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Feature Importances (Decision Tree)\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': dt_model.feature_importances_})\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(\"Top Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "\n",
    "# Plot the top 10 features\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x='Importance', y='Feature', data=top_10_features, palette='viridis', hue='Feature', legend=False)\n",
    "plt.title('Top 10 Features for Fraud Detection (Decision Tree)')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a101c13f-bb30-44c5-8d0a-af1d6950b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the confusion matrix visualizer\n",
    "cm_viz = ConfusionMatrix(dt_model, classes=['No Fraud', 'Fraud'])\n",
    "\n",
    "# Fit and evaluate the model\n",
    "cm_viz.fit(X_train, y_train)\n",
    "cm_viz.score(X_test, y_test)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c54f8f-6f85-4c6c-b05b-c7ac26c70711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Random Forest model \n",
    "\n",
    "# Define features and target variable\n",
    "X=df.drop(columns=['Provider','PotentialFraud'])\n",
    "y=df['PotentialFraud'].map({'Yes': 1, 'No': 0}) \n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  \n",
    "    ('scaler', StandardScaler())  \n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  \n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))  \n",
    "])\n",
    "\n",
    "# Combine transformations\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Create and train Random Forest model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))  # Random Forest Classifier\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions and Evaluate the Model\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Evaluate model performance with different classification metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(f'Confusion Matrix:\\n {conf_matrix}')\n",
    "\n",
    "# Visualize the ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, color='blue', label='ROC Curve')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')  \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Random Forest Classifier')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a2175-df6f-48f3-999b-f62bb75337b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for Random Forest  model\n",
    "\n",
    "# Define features and target variable\n",
    "X=df.drop(columns=['Provider','PotentialFraud'])\n",
    "y=df['PotentialFraud'].map({'Yes': 1, 'No': 0}) \n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importance from Random Forest\n",
    "feature_importances = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "feature_importance_df = feature_importances.sort_values(ascending=False).reset_index()\n",
    "feature_importance_df.columns = ['Feature', 'Importance']\n",
    "\n",
    "# Display the top 10 important features\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "print(\"Top 10 Most Important Features:\\n\", top_10_features)\n",
    "\n",
    "# Plot the top 10 features\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x='Importance', y='Feature', data=top_10_features, palette='viridis',hue='Feature',legend=False)\n",
    "plt.title('Top 10 Features for Fraud Detection (Random Forest)')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1115785-f098-4a8a-b3b5-855483f992b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "# Define features and target variable\n",
    "X=df.drop(columns=['Provider','PotentialFraud'])\n",
    "y=df['PotentialFraud'].map({'Yes': 1, 'No': 0}) \n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Create and train Random Forest model pipeline\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "cm_viz = ConfusionMatrix(model, classes=['No Fraud', 'Fraud'])\n",
    "cm_viz.fit(X_train, y_train)\n",
    "cm_viz.score(X_test, y_test)\n",
    "cm_viz.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb06ee-02a4-4008-a0b3-3b9196c37948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. XG Boost model\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['Provider', 'PotentialFraud'])\n",
    "y = df['PotentialFraud'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformations\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Calculate class weight for XGBoost\n",
    "fraud_ratio = y_train.value_counts()[0] / y_train.value_counts()[1]  # No Fraud / Fraud\n",
    "\n",
    "# Create and train XGBoost model pipeline with scale_pos_weight\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(random_state=42, scale_pos_weight=fraud_ratio, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions and Evaluate the Model\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Evaluate model performance with different classification metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(f'Confusion Matrix:\\n {conf_matrix}')\n",
    "\n",
    "# Yellowbrick Confusion Matrix\n",
    "visualizer = ConfusionMatrix(model.named_steps['classifier'], classes=['No Fraud', 'Fraud'])\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.show()\n",
    "\n",
    "# Visualize the ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, color='blue', label='ROC Curve')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')  \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for XGBoost')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1701e0f-dd82-4887-ae1f-3ee17e9eb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for XG Boost model\n",
    "# Define features and target variable\n",
    "X=df.drop(columns=['Provider','PotentialFraud'])\n",
    "y=df['PotentialFraud'].map({'Yes': 1, 'No': 0}) \n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importance from XGBoost\n",
    "feature_importances = pd.Series(xgb_model.feature_importances_, index=X.columns)\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "feature_importance_df = feature_importances.sort_values(ascending=False).reset_index()\n",
    "feature_importance_df.columns = ['Feature', 'Importance']\n",
    "\n",
    "# Display the top 10 important features\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "print(\"Top 10 Most Important Features:\\n\", top_10_features)\n",
    "\n",
    "# Plot the top 10 features\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x='Importance', y='Feature', data=top_10_features, palette='viridis',hue='Feature',legend=False)\n",
    "plt.title('Top 10 Features for Fraud Detection (XGBoost)')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25f3dbf-9a42-4018-b1b8-40c2b04e3329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. LightGBM model \n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['Provider', 'PotentialFraud'])\n",
    "y = df['PotentialFraud'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformations\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Replace NaN and Inf values\n",
    "X_train = X_train.fillna(0).replace([np.inf, -np.inf], 0)\n",
    "X_test = X_test.fillna(0).replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Create and train LightGBM model pipeline with class_weight='balanced'\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LGBMClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions and Evaluate the Model\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # Get probabilities for ROC AUC\n",
    "\n",
    "# Evaluate model performance with different classification metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(f'Confusion Matrix:\\n {conf_matrix}')\n",
    "\n",
    "# Yellowbrick Confusion Matrix\n",
    "visualizer = ConfusionMatrix(model.named_steps['classifier'], classes=['No Fraud', 'Fraud'])\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.show()\n",
    "\n",
    "# Visualize the ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, color='blue', label='ROC Curve')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')  \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for LightGBM')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4df2d7-3694-40f5-88ff-b62a35c752d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df.drop(columns=['Provider', 'PotentialFraud'])\n",
    "y = df['PotentialFraud'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train the LightGBM model with class_weight='balanced'\n",
    "lgb_model = lgb.LGBMClassifier(n_estimators=100, max_depth=5, random_state=42, class_weight='balanced')\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importance from LightGBM\n",
    "feature_importances = pd.Series(lgb_model.feature_importances_, index=X.columns)\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "feature_importance_df = feature_importances.sort_values(ascending=False).reset_index()\n",
    "feature_importance_df.columns = ['Feature', 'Importance']\n",
    "\n",
    "# Display the top 10 important features\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "print(\"Top 10 Most Important Features:\\n\", top_10_features)\n",
    "\n",
    "# Plot the top 10 features\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x='Importance', y='Feature', data=top_10_features, palette='viridis')\n",
    "plt.title('Top 10 Features for Fraud Detection (LightGBM)')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35b0fa5-5286-42f1-b033-80c58e4f0792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X=df.drop(columns=['Provider','PotentialFraud'])\n",
    "y=df['PotentialFraud'].map({'Yes': 1, 'No': 0}) \n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Fill missing numeric values with mean\n",
    "    ('scaler', StandardScaler())  # Scale numeric data\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Fill missing categorical values with most frequent\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
    "])\n",
    "\n",
    "# Combine transformations\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Create and train LightGBM model pipeline\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', lgb.LGBMClassifier(random_state=42))])  # Use LightGBM Classifier\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Visualize the confusion matrix using Yellowbrick\n",
    "cm_viz = ConfusionMatrix(model, classes=['No Fraud', 'Fraud'])\n",
    "cm_viz.fit(X_train, y_train)\n",
    "cm_viz.score(X_test, y_test)\n",
    "cm_viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec3085-d784-4cf1-900c-7ea0525eb1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. CAT Boost model \n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['Provider', 'PotentialFraud'])\n",
    "y = df['PotentialFraud'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  \n",
    "    ('scaler', StandardScaler())  \n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  \n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))  \n",
    "])\n",
    "\n",
    "# Combine transformations\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Compute class weights manually\n",
    "class_weights = {0: len(y) / (2 * sum(y == 0)), 1: len(y) / (2 * sum(y == 1))}\n",
    "\n",
    "# Create and train CatBoost model pipeline with class_weight='Balanced'\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', CatBoostClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, \n",
    "                                                          loss_function='Logloss', verbose=0, random_state=42, \n",
    "                                                          class_weights=class_weights))])  # Handling class imbalance\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "# Evaluate Model Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(f'Confusion Matrix:\\n {conf_matrix}')\n",
    "\n",
    "# Visualize the ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, color='blue', label='ROC Curve')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')  \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for CatBoost Model')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238af4f4-6abf-4dec-9e15-b83825226419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for Cat Boost \n",
    "# Define features and target variable\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['Provider','PotentialFraud'])\n",
    "y = df['PotentialFraud'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Ensure no NaN values before scaling\n",
    "X_scaled = X.fillna(0)  # Fill NaN values with 0 or use another imputation strategy\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Compute the scale_pos_weight for class imbalance\n",
    "pos_weight = len(y) / (2 * sum(y == 1))  # Scale for class 1 (fraudulent claims)\n",
    "\n",
    "# Train the CatBoost model with scale_pos_weight to handle class imbalance\n",
    "catboost_model = cb.CatBoostClassifier(iterations=100, depth=5, random_seed=42, verbose=0, scale_pos_weight=pos_weight)\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importance from CatBoost\n",
    "feature_importances = pd.Series(catboost_model.get_feature_importance(), index=X.columns)\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "feature_importance_df = feature_importances.sort_values(ascending=False).reset_index()\n",
    "feature_importance_df.columns = ['Feature', 'Importance']\n",
    "\n",
    "# Display the top 10 important features\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "print(\"Top 10 Most Important Features:\\n\", top_10_features)\n",
    "\n",
    "# Plot the top 10 features\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x='Importance', y='Feature', data=top_10_features, palette='viridis')\n",
    "plt.title('Top 10 Features for Fraud Detection (CatBoost)')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c78cbd-1053-450b-8040-e61ca01933fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models Performance comparison \n",
    "# Define features and target variable\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['Provider', 'PotentialFraud'])\n",
    "y = df['PotentialFraud'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define models with class_weight='balanced' where applicable\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, scale_pos_weight=len(y) / (2 * sum(y == 1))),  # Adjust class weight\n",
    "    \"LightGBM\": lgb.LGBMClassifier(random_state=42, class_weight='balanced'),  # Adjust class weight\n",
    "    \"CatBoost\": cb.CatBoostClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, loss_function='Logloss', verbose=0, random_state=42, scale_pos_weight=len(y) / (2 * sum(y == 1)))  # Adjust class weight\n",
    "}\n",
    "\n",
    "# To store evaluation results\n",
    "metrics = {\"Model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1-Score\": [], \"ROC-AUC\": []}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X_test)\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    # Append metrics to results\n",
    "    metrics[\"Model\"].append(name)\n",
    "    metrics[\"Accuracy\"].append(accuracy)\n",
    "    metrics[\"Precision\"].append(precision)\n",
    "    metrics[\"Recall\"].append(recall)\n",
    "    metrics[\"F1-Score\"].append(f1)\n",
    "    metrics[\"ROC-AUC\"].append(roc_auc)\n",
    "\n",
    "# Convert metrics to DataFrame for easier plotting\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Plot comparison of models with a larger figure size\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8))  \n",
    "\n",
    "# Bar chart for comparison of evaluation metrics\n",
    "metrics_df.set_index(\"Model\").plot(kind=\"bar\", ax=ax[0], color=['blue', 'orange', 'green', 'red', 'purple'], figsize=(12, 10))\n",
    "ax[0].set_title('Model Performance Comparison', fontsize=10)\n",
    "ax[0].set_ylabel('Score', fontsize=14)\n",
    "ax[0].set_ylim(0, 1)\n",
    "ax[0].set_xlabel('Model', fontsize=14)\n",
    "ax[0].tick_params(axis='x', rotation=45)  # Rotate x labels for better visibility\n",
    "ax[0].legend(loc='lower right', fontsize=12)\n",
    "\n",
    "# ROC Curve Comparison\n",
    "for name, model in models.items():\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X_test)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    ax[1].plot(fpr, tpr, label=f'{name} ROC Curve')\n",
    "\n",
    "ax[1].plot([0, 1], [0, 1], color='red', linestyle='--') \n",
    "ax[1].set_xlabel('False Positive Rate', fontsize=10)\n",
    "ax[1].set_ylabel('True Positive Rate', fontsize=8)\n",
    "ax[1].set_title('ROC Curve Comparison', fontsize=10)\n",
    "ax[1].legend(loc='lower right', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562071a9-5d1e-4051-9d32-70cb069fe8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Class Prediction Error for all models using Yellowbrick\n",
    "#CatBoostClassifier is not fully compatible with Yellowbrick's ClassPredictionError visualizer.\n",
    "# For XGBoost and LightGBM, the imbalance handling is done by setting scale_pos_weight appropriately.\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# Define models with class_weight='balanced' where applicable\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42, scale_pos_weight=len(y) / (2 * sum(y == 1))),  # Adjust class weight\n",
    "    \"LightGBM\": LGBMClassifier(verbose=-1, random_state=42, class_weight='balanced')  # Adjust class weight\n",
    "}\n",
    "\n",
    "# Set up the figure for visualization\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 12))  # 2 rows, 3 columns\n",
    "axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "\n",
    "# Loop through models and plot Class Prediction Error\n",
    "for i, (name, model) in enumerate(models.items()):\n",
    "    visualizer = ClassPredictionError(model, ax=axes[i])  # Create the visualizer\n",
    "    model.fit(X_train, y_train)  # Train model\n",
    "    visualizer.fit(X_train, y_train)  # Fit visualizer\n",
    "    visualizer.score(X_test, y_test)  # Evaluate on test data\n",
    "    visualizer.finalize()\n",
    "    axes[i].set_title(name, fontsize=14)  # Set individual plot titles\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde0293-054f-44e7-9749-701f7bb1fbff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df718499-a733-40dd-b079-dd2d25804d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad2658-014e-41c7-878b-1fcd85fc9d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29a7659-dbc6-4f18-b103-b729d409b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curve\n",
    "# Useful when dealing with imbalanced data. Highlights trade-off between precision and recall.Evaluates imbalanced fraud detection.\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define models with class_weight='balanced' where applicable\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42, scale_pos_weight=len(y) / (2 * sum(y == 1))),  # Adjust class weight\n",
    "    \"LightGBM\": LGBMClassifier(verbose=-1, random_state=42, class_weight='balanced')  # Adjust class weight\n",
    "}\n",
    "\n",
    "# Plot Precision-Recall Curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get probabilities for the positive class\n",
    "    y_probs = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute Precision-Recall curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
    "    \n",
    "    # Plot Precision-Recall curve\n",
    "    plt.plot(recall, precision, label=name)\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve for Fraud Detection Models\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be68c01-5f85-4304-8425-82c98c43f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve Comparison\n",
    "# Shows true positive rate (TPR) vs. false positive rate (FPR). Helps visualize classification threshold effectiveness.\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define models with class_weight='balanced' where applicable\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42, scale_pos_weight=len(y) / (2 * sum(y == 1))),  # Adjust class weight\n",
    "    \"LightGBM\": LGBMClassifier(verbose=-1, random_state=42, class_weight='balanced')  # Adjust class weight\n",
    "}\n",
    "\n",
    "# Plot ROC Curve Comparison\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get probabilities for the positive class\n",
    "    y_probs = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "# Add diagonal line for random classifier (no discrimination)\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64ecd16-4c1e-4036-9c5b-c9fb9c759f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (Tree-Based Models)\n",
    "# Highlights key predictors in fraud detection.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Models with class_weight='balanced'\n",
    "tree_models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42, scale_pos_weight=len(y) / (2 * sum(y == 1)))  # Adjust class weight\n",
    "}\n",
    "\n",
    "# Train the models and plot feature importance\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))  # For three tree-based models\n",
    "\n",
    "for i, name in enumerate(tree_models):\n",
    "    model = tree_models[name]\n",
    "    model.fit(X_train, y_train)  # Fit the model\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    # Sort the importances and get the feature names in the sorted order\n",
    "    indices = importances.argsort()[::-1]\n",
    "    features = X.columns[indices]\n",
    "\n",
    "    # Plot the top 10 feature importances\n",
    "    pd.Series(importances[indices], index=features).head(10).plot(kind='barh', ax=axes[i], color='darkblue')\n",
    "    axes[i].set_title(f\"{name} Feature Importance\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bbefb7-134a-4865-b48b-fed7330e7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy Comparison (Bar Chart)\n",
    "# Quick comparison of accuracy across models.\n",
    "accuracies = {name: model.score(X_test, y_test) for name, model in models.items()}\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(accuracies.keys(), accuracies.values(), color=\"skyblue\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Accuracy Comparison\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c5aff5-f2c3-456f-8d8d-375bd1a75f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration Plot\n",
    "# Measures how well predicted probabilities match actual fraud occurrence(probability reliability).\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define models with class_weight='balanced'\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42, scale_pos_weight=1),  # XGBoost handles class weights differently\n",
    "    \"LightGBM\": LGBMClassifier(verbose=-1, random_state=42, class_weight='balanced')  # LightGBM also supports class_weight='balanced'\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Train and plot the calibration curves for each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Fit model\n",
    "    y_probs = model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
    "    prob_true, prob_pred = calibration_curve(y_test, y_probs, n_bins=10)  # Calibration curve\n",
    "    plt.plot(prob_pred, prob_true, marker=\"o\", label=name)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")  # Line for perfect calibration\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Actual Fraud Probability\")\n",
    "plt.title(\"Calibration Plot for Fraud Detection Models\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42405a5-063f-414a-bf36-591d13d2e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lift Curve\n",
    "# Measures how much better the model performs(effectiveness) than random guessing\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define models with class_weight='balanced'\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42, scale_pos_weight=1),  # XGBoost handles class weights differently\n",
    "    \"LightGBM\": LGBMClassifier(verbose=-1, random_state=42, class_weight='balanced')  # LightGBM also supports class_weight='balanced'\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Train and plot the lift curve for each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Fit model\n",
    "    y_probs = model.predict_proba(X_test)[:, 1]  # Get probabilities for class 1 (fraud)\n",
    "    \n",
    "    # Get the sorted indices of predicted probabilities\n",
    "    sorted_indices = np.argsort(y_probs)[::-1]\n",
    "    \n",
    "    # Sort y_test and y_probs based on the sorted indices\n",
    "    sorted_y_test = y_test.iloc[sorted_indices]\n",
    "    sorted_probs = y_probs[sorted_indices]\n",
    "    \n",
    "    # Calculate the lift\n",
    "    lift = np.cumsum(sorted_y_test) / np.arange(1, len(y_test) + 1)\n",
    "    \n",
    "    # Plot lift curve\n",
    "    plt.plot(sorted_probs, lift, label=name)\n",
    "\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Lift\")\n",
    "plt.title(\"Lift Curve for Fraud Detection Models\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fee7371-659a-442f-8e3e-16bafddeb010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Gains Chart\n",
    "# Shows how many fraud cases are detected at different cut-off levels.Tracks fraud detection rates.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Define models with class_weight='balanced'\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42, scale_pos_weight=1),  # XGBoost handles class weights differently\n",
    "    \"LightGBM\": LGBMClassifier(verbose=-1, random_state=42, class_weight='balanced')  # LightGBM also supports class_weight='balanced'\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Train and plot the cumulative gains chart for each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Fit model\n",
    "    y_probs = model.predict_proba(X_test)[:, 1]  # Get probabilities for class 1 (fraud)\n",
    "    \n",
    "    # Calculate the false positive rate and true positive rate for ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "    \n",
    "    # Plot Cumulative Gains Chart (use tpr as the fraud detection rate)\n",
    "    plt.plot(fpr, tpr, label=name)\n",
    "\n",
    "plt.xlabel(\"Percentage of Population\")\n",
    "plt.ylabel(\"Percentage of Fraud Cases Detected\")\n",
    "plt.title(\"Cumulative Gains Chart\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a3881-bc23-46c7-bd9d-99c62cf95a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison between logistic regression without and with class-weight='Balance'\n",
    "# Define features and target variable\n",
    "X=df.drop(columns=['Provider','PotentialFraud'])\n",
    "y=df['PotentialFraud'].map({'Yes': 1, 'No': 0}) \n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Impute missing values using median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_imputed), columns=X_train_imputed.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_imputed), columns=X_test_imputed.columns)\n",
    "\n",
    "# Train Logistic Regression without class_weight\n",
    "log_reg_standard = LogisticRegression(max_iter=5000, solver='saga', random_state=42)\n",
    "log_reg_standard.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Train Logistic Regression with class_weight='balanced'\n",
    "log_reg_balanced = LogisticRegression(class_weight='balanced', max_iter=5000, solver='saga', random_state=42)\n",
    "log_reg_balanced.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_standard = log_reg_standard.predict(X_test_scaled)\n",
    "y_pred_balanced = log_reg_balanced.predict(X_test_scaled)\n",
    "\n",
    "# Compute Metrics\n",
    "metrics = {\n",
    "    \"Accuracy\": [accuracy_score(y_test, y_pred_standard), accuracy_score(y_test, y_pred_balanced)],\n",
    "    \"Precision\": [precision_score(y_test, y_pred_standard), precision_score(y_test, y_pred_balanced)],\n",
    "    \"Recall\": [recall_score(y_test, y_pred_standard), recall_score(y_test, y_pred_balanced)],\n",
    "    \"F1-score\": [f1_score(y_test, y_pred_standard), f1_score(y_test, y_pred_balanced)],\n",
    "    \"AUC-ROC\": [roc_auc_score(y_test, log_reg_standard.predict_proba(X_test_scaled)[:, 1]),\n",
    "                roc_auc_score(y_test, log_reg_balanced.predict_proba(X_test_scaled)[:, 1])]\n",
    "};\n",
    "\n",
    "# Convert to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics, index=['Logistic Regression', 'Logistic Regression (Balanced)'])\n",
    "print(metrics_df)\n",
    "\n",
    "# Feature Importance Comparison\n",
    "coefficients_standard = abs(log_reg_standard.coef_[0])\n",
    "coefficients_balanced = abs(log_reg_balanced.coef_[0])\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Standard': coefficients_standard,\n",
    "    'Balanced': coefficients_balanced\n",
    "}).sort_values(by='Standard', ascending=False);\n",
    "\n",
    "# Plot Feature Importance\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = feature_importance_df.head(10).plot(kind='barh', x='Feature', figsize=(8, 6), width=0.7)\n",
    "plt.title('Feature Importance Comparison (Logistic Regression)')\n",
    "plt.xlabel('Importance (Absolute Coefficient)')\n",
    "plt.ylabel('Feature')\n",
    "plt.legend(['Standard', 'Balanced'])\n",
    "plt.gca().invert_yaxis()  # Reverse order for better visualization\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dced8d7-3e25-42ba-92f0-ed95fd4cde30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison between Logistic Regression with and without class_weight\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['Provider','PotentialFraud'])\n",
    "y = df['PotentialFraud'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define models: Logistic Regression with and without class_weight='balanced'\n",
    "models = {\n",
    "    \"Logistic Regression (No Class Weight)\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Logistic Regression (With Class Weight Balanced)\": LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "}\n",
    "\n",
    "# To store evaluation results\n",
    "metrics = {\"Model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1-Score\": [], \"ROC-AUC\": []}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Append metrics to results\n",
    "    metrics[\"Model\"].append(name)\n",
    "    metrics[\"Accuracy\"].append(accuracy)\n",
    "    metrics[\"Precision\"].append(precision)\n",
    "    metrics[\"Recall\"].append(recall)\n",
    "    metrics[\"F1-Score\"].append(f1)\n",
    "    metrics[\"ROC-AUC\"].append(roc_auc)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(f'\\n{name}')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1-score: {f1:.4f}')\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "    print(f'Confusion Matrix:\\n {conf_matrix}')\n",
    "\n",
    "\n",
    "    # Feature Importance (coefficients for Logistic Regression)\n",
    "    feature_importance = np.abs(model.coef_[0])\n",
    "    feature_names = X.columns\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "\n",
    "    # Plot feature importances\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_names[sorted_idx], feature_importance[sorted_idx], color='skyblue')\n",
    "    plt.title(f'Feature Importances for {name}')\n",
    "    plt.xlabel('Absolute Coefficient Value')\n",
    "    plt.ylabel('Features')\n",
    "    plt.show()\n",
    "\n",
    "# Convert metrics to DataFrame for easier comparison\n",
    "import pandas as pd\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Print the metrics DataFrame\n",
    "print(metrics_df)\n",
    "\n",
    "# Optional: Plot the comparison of metrics\n",
    "metrics_df.set_index(\"Model\").plot(kind=\"bar\", figsize=(10, 6), color=['blue', 'orange', 'green', 'red', 'purple'])\n",
    "plt.title('Logistic Regression Comparison (With and Without Class Weight)', fontsize=14)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0790bea2-d111-46c0-88f1-9d6900af039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison between Logistic Regression with and without class_weight\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['Provider','PotentialFraud'])\n",
    "y = df['PotentialFraud'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train two models: one without class_weight and one with class_weight='balanced'\n",
    "log_reg_standard = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_standard.fit(X_train, y_train)\n",
    "\n",
    "log_reg_balanced = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "log_reg_balanced.fit(X_train, y_train)\n",
    "\n",
    "# Create subplots for confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Visualize confusion matrix for standard Logistic Regression\n",
    "cm_standard_viz = ConfusionMatrix(log_reg_standard, ax=axes[0])\n",
    "cm_standard_viz.fit(X_train, y_train)\n",
    "cm_standard_viz.score(X_test, y_test)\n",
    "axes[0].set_title('Confusion Matrix (Logistic Regression)')\n",
    "\n",
    "# Visualize confusion matrix for Logistic Regression with class_weight='balanced'\n",
    "cm_balanced_viz = ConfusionMatrix(log_reg_balanced, ax=axes[1])\n",
    "cm_balanced_viz.fit(X_train, y_train)\n",
    "cm_balanced_viz.score(X_test, y_test)\n",
    "axes[1].set_title('Confusion Matrix (Logistic Regression with Balanced Weight)')\n",
    "\n",
    "# Display the confusion matrices\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Predictions for evaluation metrics (standard logistic regression)\n",
    "y_pred_standard = log_reg_standard.predict(X_test)\n",
    "y_prob_standard = log_reg_standard.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute evaluation metrics for standard logistic regression\n",
    "accuracy_standard = accuracy_score(y_test, y_pred_standard)\n",
    "precision_standard = precision_score(y_test, y_pred_standard)\n",
    "recall_standard = recall_score(y_test, y_pred_standard)\n",
    "f1_standard = f1_score(y_test, y_pred_standard)\n",
    "roc_auc_standard = roc_auc_score(y_test, y_prob_standard)\n",
    "\n",
    "print(f\"Standard Logistic Regression Metrics:\")\n",
    "print(f'Accuracy: {accuracy_standard:.4f}')\n",
    "print(f'Precision: {precision_standard:.4f}')\n",
    "print(f'Recall: {recall_standard:.4f}')\n",
    "print(f'F1-score: {f1_standard:.4f}')\n",
    "print(f'ROC-AUC: {roc_auc_standard:.4f}')\n",
    "\n",
    "# Predictions for logistic regression with class_weight='balanced'\n",
    "y_pred_balanced = log_reg_balanced.predict(X_test)\n",
    "y_prob_balanced = log_reg_balanced.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute evaluation metrics for logistic regression with class_weight='balanced'\n",
    "accuracy_balanced = accuracy_score(y_test, y_pred_balanced)\n",
    "precision_balanced = precision_score(y_test, y_pred_balanced)\n",
    "recall_balanced = recall_score(y_test, y_pred_balanced)\n",
    "f1_balanced = f1_score(y_test, y_pred_balanced)\n",
    "roc_auc_balanced = roc_auc_score(y_test, y_prob_balanced)\n",
    "\n",
    "print(f\"\\nLogistic Regression with Balanced Weight Metrics:\")\n",
    "print(f'Accuracy: {accuracy_balanced:.4f}')\n",
    "print(f'Precision: {precision_balanced:.4f}')\n",
    "print(f'Recall: {recall_balanced:.4f}')\n",
    "print(f'F1-score: {f1_balanced:.4f}')\n",
    "print(f'ROC-AUC: {roc_auc_balanced:.4f}')\n",
    "\n",
    "# Visualize ROC Curve for comparison\n",
    "fpr_standard, tpr_standard, thresholds_standard = roc_curve(y_test, y_prob_standard)\n",
    "fpr_balanced, tpr_balanced, thresholds_balanced = roc_curve(y_test, y_prob_balanced)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr_standard, tpr_standard, color='blue', label='Standard Logistic Regression')\n",
    "plt.plot(fpr_balanced, tpr_balanced, color='green', label='Logistic Regression with Balanced Weight')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a26605-f530-44e8-9a2c-a5ea2ce271d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
